services:
  postgres:
    image: postgres:15-alpine
    container_name: postgres
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./postgres/init-scripts:/docker-entrypoint-initdb.d:ro
    networks:
      - internal
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    restart: unless-stopped

  n8n:
    build: .
    image: customizedn8n  # Imagen personalizada con el nodo de LangChain
    container_name: n8n
    environment:
      - DB_TYPE=postgresdb
      - DB_POSTGRESDB_HOST=postgres
      - DB_POSTGRESDB_PORT=5432
      - DB_POSTGRESDB_DATABASE=${POSTGRES_DB}
      - DB_POSTGRESDB_USER=${POSTGRES_USER}
      - DB_POSTGRESDB_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
      - N8N_DIAGNOSTICS_ENABLED=${N8N_DIAGNOSTICS_ENABLED}
      - OLLAMA_HOST=http://ollama:11434
      - N8N_WEBHOOK_TUNNEL_URL=${N8N_WEBHOOK_TUNNEL_URL}
      - N8N_DEFAULT_EXECUTION_MODE=${N8N_DEFAULT_EXECUTION_MODE}
      - N8N_USER=n8n
      - N8N_UID=1000
      - N8N_GID=1000
      - N8N_ENCRYPTION_KEY=${N8N_ENCRYPTION_KEY}
      - N8N_PROTOCOL=http
      - GENERIC_TIMEZONE=${GENERIC_TIMEZONE}
      - TZ=${TZ}
      - N8N_EDITOR_CREDENTIAL_STORE_MODE=postgresql
      - N8N_EDITOR_CREDENTIAL_STORE_CONNECTION_STRING=postgresql://${DB_POSTGRESDB_USER}:${DB_POSTGRESDB_PASSWORD}@${DB_POSTGRESDB_HOST}:${DB_POSTGRESDB_PORT}/${DB_POSTGRESDB_DATABASE}
      - N8N_RUNNERS_ENABLED=true
      - N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS=true
      - OLLAMA_API_BASE_URL=http://ollama:11434
      - N8N_OLLAMA_HOST=http://ollama:11434
    ports:
      - "${N8N_PORT}:5678"
    volumes:
      - n8n_data:/home/node/.n8n
      - n8n_logs:/var/log/n8n
      - n8n_config:/home/node/config
      - ./postgres/init-scripts:/docker-entrypoint-initdb.d:ro
    networks:
      - internal
    depends_on:
      postgres:
        condition: service_healthy
      ollama:
        condition: service_started
    restart: unless-stopped

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    runtime: nvidia
    ports:
      - "${OLLAMA_PORT}:11434"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [compute, utility]
              options:
                memory: 4000M          # Reducido para evitar saturación
        limits:
          memory: 8G              # Reducido ya que solo usa 1.2GB
          cpus: '4'               # Ajustado para mejor rendimiento
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0
      - OLLAMA_GPU_MEMORY=3500        # Reducido por advertencias
      - OLLAMA_GPU_LAYERS=25          # Reducido por VRAM
      - OLLAMA_BATCH_SIZE=512         # Ajustado para memoria disponible
      - OLLAMA_NUM_THREAD=6           # Ajustado para Max-Q Design
      - OLLAMA_FLASH_ATTENTION=true
      - OLLAMA_CONCURRENT_REQUESTS=4   # Reducido para evitar sobrecarga
      - OLLAMA_CONTEXT_LENGTH=2048    # Reducido para ahorrar memoria
      - OLLAMA_GPU_SPLIT_SIZE=128     # Ajustado para GTX 1660 Ti
      - OLLAMA_F16=true               # Nuevo: usar precisión FP16
    volumes:
      - ollama_data:/root/.ollama
      - ollama_models:/root/.ollama/models
    networks:
      - internal
    restart: unless-stopped

networks:
  internal:
    driver: bridge

volumes:
  postgres_data:
  postgres_init:
  n8n_data:
  n8n_logs:
  n8n_config:
  ollama_data:
  ollama_models:
